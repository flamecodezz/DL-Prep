{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 数学知识：矩阵理论，概率论等\n",
    "## 2.线性代数\n",
    "\n",
    "### 2.1 标量，向量，矩阵和张量\n",
    "- 标量：属于一个数域中的数\n",
    "- 向量：每个元素属于某个数域的一列有序排列的数，元素值代表空间中坐标轴的坐标\n",
    "- 矩阵：二维数组\n",
    "- 张量：一个元素分布在若干维坐标的规则网络中的数组\n",
    "### 2.2 矩阵和向量相乘：\n",
    "\n",
    "   其中对应元素相乘被称为hadamard乘积。矩阵相乘满足分配律和结合律，但不一定满足交换律\n",
    "\n",
    "### 2.3 单位矩阵和逆矩阵：原矩阵和其逆矩阵相乘为单位阵, **可逆的条件是方阵而且有n个线性无关的列向量**\n",
    "\n",
    "### 2.4 线性相关和生成子空间：\n",
    "\n",
    "- 线性方程组有一个解或者无穷多个解，如果假设只有两个解，那么这两个解的线性组合也是线性方程组的解\n",
    "- 线性方程组的解：什么样的A的列向量的组合方式可以到达b,**其中b为m维实数域的任意向量**. —>当且仅当线性方程组中A 有且仅有m个线性无关的列向量(列向量总数大于m时,有无穷多个解)时, 该方程有解\n",
    "- 生成子空间: 原始向量线性组合能到达的向量的集合\n",
    "\n",
    "### 2.5 范数:衡量向量大小的函数\n",
    "\n",
    "$$||x||_p = \\Bigg(\\sum_i |x_i|^p\\Bigg)^{1/p}$$\n",
    "\n",
    "- 范数是 **满足下列性质的任意函数** :\n",
    "    - 零向量函数值为0\n",
    "    - 和的函数值小于函数值的和\n",
    "    - 数乘后向量的函数值等于数和原函数相乘\n",
    "- 为了区分零和非零元素之间的差异—L1范数\n",
    "\n",
    "    $$||x||_1 = \\sum_i|x_i|$$\n",
    "\n",
    "- 最大（无穷）范数：\n",
    "\n",
    "    $$||x||_\\infty = max_i|x_i|$$\n",
    "\n",
    "- F范数—衡量矩阵的大小\n",
    "\n",
    "$$||A||_F = \\sqrt{\\sum_{i,j} A_{i,j}^2}$$\n",
    "\n",
    "- 特殊的矩阵和向量：\n",
    "- 对角矩阵\\lambda： 只有主对角线上含有非零元素，逆矩阵为对角线元素的倒数。\\lambda * x 为x中每个元素放缩。瘦长的矩阵在向量后加上零元素，胖的矩阵会去掉一些元素\n",
    "- 单位向量：具有单位范数的向量\n",
    "\n",
    "    $$||x||_2 = 1$$\n",
    "\n",
    "- 标准正交基：在n维空间里，n个两两正交的且范数为1 的正交基。\n",
    "\n",
    "    $$x^Ty = 0 $$\n",
    "\n",
    "- 正交矩阵：\n",
    "\n",
    "    $$A^TA = AA^T = I \\Rightarrow A^{-1} = A^T$$\n",
    "\n",
    "## 3.概率和信息论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.数值计算\n",
    "\n",
    "解决在有限的物理内存里表达实数带来的误差问题\n",
    "\n",
    "### 4.1 上溢和下溢\n",
    "\n",
    "下溢：非0数被四舍五入成0导致除法和取对数运算返回非法值\n",
    "\n",
    "上溢：很大的数被近似为正负无穷\n",
    "\n",
    "在softmax函数中上溢和下溢问题同时存在，利用将原输入减去一个基准值解决这个问题（前提是自变量减去或加上一个数不会使得原函数值发生变化）\n",
    "\n",
    "### 4.2 病态条件\n",
    "\n",
    "条件数用于衡量矩阵产生扰动时运算输出的变化，例如f = (A^-1)*x中条件数为最大和最小特征值的模之比，当条件数大时，求逆运算对输入误差敏感\n",
    "\n",
    "### 4.3基于梯度的优化方法\n",
    "\n",
    "基于梯度的一维搜索得到最速下降的迭代点时：\n",
    "\n",
    "$$x' = x-\\epsilon \\nabla_x f(x) \\ \\ \\ \\nabla_x f(x)\\ is\\ the\\ gradient $$\n",
    "\n",
    "选择学习率时，可以采用几个学习率中得到更新函数值更小的那个。可能有利于跳过\n",
    "\n",
    "#### 4.3.1 雅可比和海森矩阵\n",
    "\n",
    "- 雅可比矩阵：对于输入输出都是向量的函数，所有一阶偏导数组成的矩阵称为雅可比矩阵\n",
    "- 海森矩阵：一阶偏导数对于另一个自变量的导数构成的矩阵是海森矩阵\n",
    "\n",
    "    **海森矩阵的特征值刻画学习率的量级**：特征值刻画在特征向量方向和特征向量相近二阶方向导数的最大值和最小值，从而在泰勒函数近似函数值的变化时可以描述学习率的量级。由计算得，最优步长应该为：\n",
    "\n",
    "    $$\\epsilon^* = (g^Tg)/(g^THg)\\ \\ \\ g\\ is \\ the\\ gradient$$\n",
    "\n",
    "    **判断局部极大点，局部极小点和鞍点：当一阶导数等于0时，根据二阶导数的正负判断**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
