{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 面试题\n",
    "将见过的面试题和自己想到查到的回答\n",
    "\n",
    "* [1. 训练加速](#1.训练加速)\n",
    "    * 数据并行\n",
    "    * 数据并行(nn.distributed) \\* [todo]\n",
    "    * 模型并行  \n",
    "    * pytorch的dataparallel\n",
    "\n",
    "* [2. 目标检测](#2.目标检测)\n",
    "    * 1.算法有哪些？他们的对比？\n",
    "        * RCNN：\n",
    "        * fast RCNN\n",
    "        * faster RCNN\n",
    "        * YOLO\n",
    "        * SSD\n",
    "    * 2.简述一下YOLOv2的原理，v1和v2有什么区别？\n",
    "    * 3.非极大抑制是什么，有什么作用？\n",
    "    * 4.如何实现mOU 和非极大抑制？即手推计算过程。 \\* [todo]\n",
    "    * 5.nms的发展（greedy-nms，soft-nms，fast-nms，matrix-nms） \\* [todo]\n",
    "    * 6.YOLOv2为什么将输入尺寸从448降到416 \n",
    "    * 7.YOLOv2对于anchor的使用与faster-rcnn有何不同\n",
    "    * 8.YOLOv2,v3一个GT可以对应几个anchor？SSD呢？RCNN系列呢？\n",
    "    * 9.YOLOv3对于v2做了怎样的改进？\n",
    "    * 10.YOLOv2与v3筛选正负样本的方式类似，具体是怎样进行的？这种操作解决了什么问题？\n",
    "    * 11.YOLOv3的多尺度输出结构与FPN有何不同？\n",
    "    * 12.YOLOv2,v3的anchor聚类如何做？指标是什么？\n",
    "    * 13.FPN的多尺度输出结构与SSD的多尺度输出结构哪个效果更好\n",
    "    * 14.faster-rcnn在撒anchor的时候，是如何把特征图坐标映射到图像上的？\n",
    "    * 15.faster-rcnn的OHEM与ssd的OHEM有何不同\n",
    "    * 16.roi pooling与roi align的具体操作\n",
    "    * 17.retinanet解决了以往one-stage检测器的什么问题\n",
    "    * 18.Focal loss一定有效吗？为什么？试举出一个例子\n",
    "    * 19.介绍cascade-RCNN和DCN模块。Cascade-rcnn解决了什么问题？cascade-RCNN一般选用几个阶段？\n",
    "    * 20.anchor-free的方式大概分为哪两种？各有什么特点？\n",
    "    * 21.coco的mAP的计算公式\n",
    "    \n",
    "* [3. 循环卷积神经网络](#3.循环卷积神经网络)\n",
    "    * 1.LSTM为什么会导致梯度爆炸？要如何解决？\n",
    "\n",
    "* [4. 语义分割](#4.语义分割)\n",
    "    * 1.主要语义分割的算法有哪些，他们有什么区别？\n",
    "        * FCN\n",
    "        * Unet\n",
    "        * SegNet\n",
    "        * Deeplab\n",
    "        * PSPNet\n",
    "    * 2.感受野会受到什么因素的影响？怎么影响？\n",
    "        * 池化，stride，空洞卷积，网络深度等\n",
    "    * 3.遥感图像语义分割和普通图像的语义分割有什么区别？\n",
    "    * 4.语义分割中的样本均衡介绍一下？\n",
    "    * 5.双线性插值，转置卷积和反卷积的区别与联系 \\* [todo]\n",
    "    * 6.介绍语义分割、实例分割和全景分割 \\* [todo]\n",
    "    * 7.后处理方法：CRF \\* [todo]\n",
    "\n",
    "* [5. Backbone](#5.Backbone)\n",
    "    * 1.resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？\n",
    "    * 2.ResNet和ResNeXt的区别 \\* [todo]  \n",
    "    * 3.Inception中的deep supervision有什么作用 \\* [todo]  \n",
    "    * 4.resnet的shortcut结构有什么缺点?如何改进?  \n",
    "    * 5.resnet的post activation有什么作用?  \n",
    "    * 6.shufflenet的shuffle操作如何进行?\n",
    "\n",
    "* [6. 卷积神经网络基础](#6.卷积神经网络基础)\n",
    "    * 1.Batch Normalization 在卷积神经网络中的作用是什么?\n",
    "    * 2.1*1卷积的作用是什么？\n",
    "    * 2.1. 深度可分离卷积介绍一下？\n",
    "    * 3.两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？\n",
    "    * 4.不同激活函数有什么区别？\n",
    "    * 5.卷积层输出大小的计算?\n",
    "    * 5.1. 常规卷积的计算量是多少？\n",
    "    * 6.dropout层为什么可以促进正则化？pytorch中dropout在训练与测试时如何使用？\n",
    "    * 7.平方误差损失函数和交叉熵损失函数分别适用于什么场景？\n",
    "    * 8.梯度消失/爆炸的原因?\n",
    "    * 9.损失降不下来怎么办？\n",
    "    * 10.weight decay vs L2 正则项\n",
    "    * 11.avarage-pooling与max-pooling的区别与联系？它们的梯度反传如何进行？\n",
    "    * 12.各种normalization层了解多少？(包括SyncBN)\n",
    "    * 13.为什么学习率的设置要与batchsize成线型关系\n",
    "    * 14.ReLU有哪些改进的方式\n",
    "    * 15.神经网络中参数中的偏置bias有什么作用\n",
    "    * 16.caffe的im2col是怎么操作的？ \\* [todo]\n",
    "\n",
    "* [7. 神经网络训练场景问题](#7.神经网络训练场景问题)\n",
    "    * 1.怎么判断过拟合，怎么处理？\n",
    "\n",
    "* [8. Python](#8.Python)\n",
    "    * 1.装饰器是什么，有什么作用？\n",
    "    * 2.迭代器\n",
    "    * 3.生成器\n",
    "    * 4.深拷贝与浅拷贝的区别 \n",
    "    * 5.Python中is和==的区别\n",
    "    * 6.解释with语句\n",
    "    * 7.什么是面向对象？面向过程和面向对象的区别？\n",
    "    \n",
    "\n",
    "* [9. 机器学习](#9.机器学习)\n",
    "    * 1.讲讲支持向量机，间隔，对偶，核技巧，如何将分类问题转化成最优化问题的（手推公式）？ \\* [todo]\n",
    "    * 2.讲解逻辑回归和手写逻辑回归的损失函数 \\* [todo]\n",
    "    * 3.集成学习中的三大块介绍一下？\n",
    "    \n",
    "* [10. 传统图像处理](#10.传统图像处理)  \n",
    "    * 1.直方图均衡  \n",
    "    * 2.直方图匹配  \n",
    "    * 3.SIFT的特点  \n",
    "    * 4.刚体变换，仿射变换，透视变换（投影变换）  \n",
    "    * 5.索贝尔算子长什么样?为什么长这样?\n",
    "    * 6.拉普拉斯边算子?  \n",
    "    * 7.图像亮度、对比度、饱和度 \n",
    "    * 8.高斯金字塔与拉普拉斯金字塔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.训练加速\n",
    "1. 使用多块GPU时要如何设置？\n",
    "\n",
    "### 数据并行：\n",
    "1. 将CUDA_VISIBLE_DEVICES设置成想要运行的几块卡\n",
    "2. 使用nn.DataParallel函数将模型包起来，并传入指定的GPU\n",
    "3. 将模型和数据都.cuda() 传入GPU\n",
    "\n",
    "#### Pytorch 的 DataParallel：  \n",
    "&ensp;&ensp;&ensp;&ensp;流程图如下：  \n",
    "\n",
    "![avatar](./Pics/dp_0.png)\n",
    "\n",
    "&ensp;&ensp;&ensp;&ensp;总的来说就是：复制module-分发数据-forward-计算loss-backward-汇总梯度-更新参数-复制module-...一直循环。  \n",
    "&ensp;&ensp;&ensp;&ensp;前传以及反传过程如下图：  \n",
    "![avatar](./Pics/dp_1.jpg)  \n",
    "&ensp;&ensp;&ensp;&ensp;**注意某个参数梯度是先在各卡上分别计算出来再相加**\n",
    "\n",
    "\n",
    "数据并行（ nn.distributed ）--需要有batchsize>1才可以\n",
    "**todo**\n",
    "\n",
    "模型并行：\n",
    "1. 将模型通过在模型定义的部分拆分到几块不同的显卡上\n",
    "2. 在forward部分将数据传到对应的显卡并前传  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.目标检测\n",
    "1.算法有哪些？他们的对比？\n",
    "主要算法有 rcnn（region-convnet）系列，SSD，Retina net，yolov1v2v3 等，其中 rcnn 网络为多/两阶段网络，即我们需要对网络中的多/两个模块分别训练来获得最后的训练结果，其缺点在于速度较慢，优点在于准确度较高。\n",
    "1. RCNN：\n",
    "\n",
    "    ![Pics/Untitled.png](Pics/Untitled.png)\n",
    "\n",
    "    1. 首先使用selective search（评估图像相邻部分的相似度并将相似度高的部分合并并打分，选出评分较高的2000个子图）在原始图片中选择出子图；\n",
    "\n",
    "    2. 随后将提取出的子图进行warp，从而采用一个统一的大小，同样大小的子图输入特征提取网络（卷积-relu-池化-全连接）进行特征提取；\n",
    "\n",
    "    3. 根据每个子图提取的特征进行分类，保留某一类打分较高的区块，作为物体的最终定位区块\n",
    "\n",
    "    它较慢的原因主要在于一张图片要提取2000个子图，每个子图都要做特征提取，相当于对一张图片进行了多次重复的前向传播，计算效率大大降低\n",
    "\n",
    "2. Fast RCNN：\n",
    "        \n",
    "    ![https://img.mukewang.com/5b2bbbd6000129a213380536.jpg](https://img.mukewang.com/5b2bbbd6000129a213380536.jpg)\n",
    "\n",
    "    1. 引入ROI-pooling结构，在将图片warp的部分改为使用ROI pooling，因为特征提取网络中采用了全连接神经网络，因此传入全连接层的特征图大小必须一致，之前采用了对原始图片进行warp，这样容易使得图片产生形变和信息丢失，而且这个操作较费事，现在采用ROI pooling，即根据变换后图片的尺寸例如M\\*N，将特征图分为M\\*N个方格，并取出其中的最大值（最显著的特征），加快了操作。\n",
    "    2. 提出多任务损失的思想，将分类损失和边框定位损失结合在一起统一训练。\n",
    "    3. 将整图只通过一次CNN网络就提取所有ROI的特征。因为2000个子图在原图上有很多重叠，因此每个子图都通过一个特征提取网络是费时费力的，因此，通过区域投影的方式，将整图通过特征提取网络，再利用区域投影将整图的特征取出ROI的那一部分，即可通过一次特征提取网络，得到所有的ROI的特征\n",
    "\n",
    "3. Faster RCNN：\n",
    "    ![pic](Pics/detection.jpg)\n",
    "    \n",
    "    这一部分的过程较复杂，总结起来就是先通过 Backbone 网络提取特征，然后基于特征进行和 Anchor 训练 RPN 网络获取 Anchor 偏差的估计，在偏差估计的基础上获得proposal，（同时我们还需要在 RPN 网络进行正负样本标签的预测从而方便筛选 proposals，最后根据获得的正负样本标签和 NMS 筛选出2000 个 proposals）, 随后，将获得的 proposals 位置投影到特征图上获得 ROI，然后基于 ROI 进行 ROI Align，并输入到 FCN 进行类别标签预测，和偏移位置的计算，具体的流程可以见[这里](https://zhuanlan.zhihu.com/p/133467109)\n",
    "\n",
    "    这个部分的改进是将原本的ROI提取方法—selective search 改为了Region Proposal Network，这样大大增加了提取目标框的速度。RPN网络通过在原始卷积层上提取的特征经过进一步3\\*3卷积增加感受野，得到了提取ROI和调整ROI边界两个支路，\n",
    "\n",
    "    1. 在提取ROI支路上，基于之前在CONV5的特征图上每一个点生成的k个anchor，随后通过1\\*1卷积获得W\\*H\\*18的输出结果，这个结果代表每个点9个anchor，前景和背景的两个结果，随后通过reshape和softmax得到概率，区分目标是前景还是后景（这一步的判断是为了去除大量无用的背景anchor）；\n",
    "\n",
    "    2. 另一条通过1\\*1卷积reshape到36层的特征图是对应于bbox相对于原始anchor的偏移量，由于通过四个线性变换参数，anchor就可以变换中心点位置和长宽，从而变换到接近到GT的bbox坐标，因此通过原始特征图变换就可以得到这四个参数，由于每个点有9个anchor，同时每个anchor需要四个参数调整位置，因此这一层的输出有36层；\n",
    "\n",
    "   其中输出结果的形状计算如下，VGG输出50\\*38\\*512的特征，对应设置50\\*38\\*k个anchors，而RPN输出：1.大小为50\\*38\\*2k 的positive/negative softmax分类特征矩阵; 2. 大小为50\\*38\\*4k的regression坐标回归特征矩阵\n",
    "\n",
    "   最后proposal层综合主要的前景anchors和对应的偏移量结合NMS和一些筛选方法获取proposal；其实RPN最终就是在原图尺度上，设置了密密麻麻的候选Anchor。然后用cnn去判断哪些Anchor是里面有目标的positive anchor，哪些是没目标的negative anchor。所以，仅仅是个二分类而已！\n",
    "\n",
    "4. YOLO\n",
    "\n",
    "    ![Pics/Untitled%202.png](Pics/Untitled%202.png)\n",
    "\n",
    "    在网络结构上，YOLO分为三个部分，第一个部分是特征提取网络，用于提取有用的可泛化的特征，第二部分为目标检测网络，在目标检测网络之后，就获得了7\\*7\\*30的输出结果，这个部分相当于将原图分为了7\\*7的网格，每个网格预测两个长宽不同的anchor的位置和长宽，以及这两个anchor的置信分数（是否有目标\\*和真实bbox的IOU）以及这个格子内的物体属于哪一个类别。\n",
    "\n",
    "    将原图划分成S\\*S大小的格子，每个格子用于预测中心点落在格子内的目标。\n",
    "    每个各自预测B个边界框和他们对应的置信度（置信度是边界框中有目标的概率\\*这个边界框的准确度，用IOU来衡量）。\n",
    "    而为了表示边界框，需要使用（x,y,w,h）表示，结合上置信度，则每个边界框预测（x,y,w,h,c）。\n",
    "    除此之外，对于每个格子会预测一组条件类别概率C，因此每个格子会产生（B\\*5+C）大小的向量，总共就是（S\\*S,B\\*5+C）\n",
    "\n",
    "    ![Pics/Untitled%203.png](Pics/Untitled%203.png)\n",
    "\n",
    "    损失函数中，使用了MSEloss，对于不同类别的误差采取了系数进行调控。\n",
    "\n",
    "    yolo算法开创了one-stage检测的先河，它将物体分类和物体检测网络合二为一，都在全连接层完成。故它大大降低了目标检测的耗时，提高了实时性。但它的缺点也十分明显\n",
    "\n",
    "    1. 每个网格只对应两个bounding box，当物体的长宽比不常见（也就是训练数据集覆盖不到时），效果很差。\n",
    "    2. 原始图片只划分为7x7的网格，当两个物体靠的很近时，效果很差\n",
    "    3. 最终每个网格只对应一个类别，容易出现漏检（物体没有被识别到）。\n",
    "    4. 对于图片中比较小的物体，效果很差。这其实是所有目标检测算法的通病，SSD对它有些优化，我们后面再看。\n",
    "\n",
    "5. SSD Single Shot MultiBox Detector\n",
    "\n",
    "    ![Pics/Untitled%204.png](Pics/Untitled%204.png)\n",
    "\n",
    "    相比Yolo，SSD采用CNN来直接进行检测，而不是像Yolo那样在全连接层之后做检测。SSD提取了不同尺度的特征图来做检测，大尺度特征图（较靠前的特征图）可以用来检测小物体，而小尺度特征图（较靠后的特征图）用来检测大物体；\n",
    "\n",
    "    SSD采用了不同尺度和长宽比的先验框（Prior boxes, Default boxes，在Faster R-CNN中叫做锚，Anchors）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 简述一下YOLOv2的原理，v1和v2有什么区别？\n",
    "    1. 增加了BN层：对于每个隐层神经元，避免梯度消失问题。YOLO网络在每一个卷积层后添加batch normalization，通过这一方法，mAP获得了2%的提升\n",
    "    2. 使用更大图片为输入的分类器，然后finetune到检测网络：新的YOLO网络在分类任务时把分辨率直接提升到了448 * 448，这也意味之原有的网络模型必须进行某种调整以适应新的分辨率输入。作者首先对分类网络（自定义的darknet）进行了fine tune，分辨率改成448 * 448，在ImageNet数据集上训练10轮（10 epochs），训练后的网络就可以适应高分辨率的输入了。然后，作者对检测网络部分（也就是后半部分）也进行fine tune。这样通过提升输入的分辨率，mAP获得了4%的提升。\n",
    "    3. 增加了Anchorbox的思想，增加网络的召回率：YOLO利用全连接层的数据完成边框的预测，导致丢失较多的空间信息，定位不准。作者在去掉了全连接层之后加入了anchor box（维度聚类之后），加入了anchor boxes后，可以预料到的结果是召回率上升，准确率下降。现在总共会预测13 * 13 * 9 = 1521个boxes，而之前的网络仅仅预测7 * 7 * 2 = 98个boxes\n",
    "\n",
    "3. 非极大抑制是什么，有什么作用？\n",
    "\n",
    "    NMS算法主要解决的是一个目标被多次检测的问题，在生成较多Anchor时，对于同一个目标会被检测到多次，因此我们希望保留最有效的Anchor，把其他的去掉。那么可以采用NMS算法来实现这样的效果：首先从所有的检测框中找到置信度最大的那个框作为基准框，然后挨个计算其与剩余框的IOU，如果其值大于一定阈值（重合度过高），那么就将该框剔除，循环这个过程，直到所有的检测框都成为过基准框，这也就说明所有的检测框和其他的检测框都仅有较小的重合率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 如何计算 Anchor 和真实 bbox 之间的 mIOU，以及如何在此基础上进行 NMS 算法？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(box1, box2):\n",
    "    \"\"\"\n",
    "    box1: represent as in (xmin, ymin, xmax, ymax)\n",
    "    box2: represent as in (xmin, ymin, xmax, ymax)\n",
    "    \"\"\"\n",
    "    leftdown = max(box1[:2], box2[:2])\n",
    "    rightup = min(box1[2:], box2[2:])\n",
    "    intersect = (rightup[0] - leftdown[0]) * (rightup[1] - leftdown[1])\n",
    "    union = (box1[3]-box1[1])*(box1[2]-box1[0]) + (box2[3]-box2[1])*(box2[2]-box2[0]) - intersect\n",
    "    \n",
    "    return intersect/union\n",
    "    \n",
    "def compute_intersection(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的交集\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
    "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
    "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
    "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
    "\n",
    "\n",
    "def compute_jaccard(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的Jaccard系数(IoU)\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # Find intersections\n",
    "    intersection = compute_intersection(set_1, set_2)  # (n1, n2)\n",
    "\n",
    "    # Find areas of each box in both sets\n",
    "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
    "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
    "\n",
    "    # Find the union\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
    "\n",
    "    return intersection / union  # (n1, n2)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. YOLOv2在检测时为什么将输入尺寸从448降到416:  \n",
    "    为了使得输入下采样32倍后的输出为奇数13.对于图片中大的物体,其中心往往落在图片的中心区域,奇数倍的输出有一个明确的中心cell,这样对于这类大的物体能够更好的训练.若是偶数倍的输出,大物体的中心可能会落在中心的两个区域.  \n",
    "\n",
    "\n",
    "7. YOLOv2对于anchor的使用与faster-rcnn有何不同:\n",
    "    YOLO系列只使用anchor做box的wh的回归,且规则与faster-rcnn一样,YOLO的中心点定位方法一直使用的是offset的预测,**并未使用anchor做box中心的定位.所以,YOLO在利用anchor确定正负样本时,使用的是相对IOU,即把GT拉到与anchor同一个中心点来计算IOU.而faster-rcnn是计算的绝对IOU.**.  \n",
    "\n",
    "\n",
    "8. YOLOv2,v3一个anchor可以对应几个GT？SSD呢？RCNN系列呢？  \n",
    "    YOLO中,一个GT只对应一个anchor,而SSD与faster-rcnn一个GT往往对应多个anchor \n",
    "    \n",
    "\n",
    "9. YOLOv3对于v2做了怎样的改进？  \n",
    "    v3再次修改了backbone，使用了类似FPN的多尺度输出结构，只不过特征融合用的是concatenate，同时，obj与class都使用BCE来训练,V3之前的所有损失均用MSE来计算  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "10. YOLOv2与v3筛选正负样本的方式类似，具体是怎样进行的？这种操作解决了什么问题？  \n",
    "   1. 首先确定GT的中心落入哪个grid cell,没有GT落入的cell内的anchor全部表位non-obj,只参加objectness的损失.\n",
    "   2. 对于有GT落入的cell内,选择与GT的iou最大的anchor作为正样本,cell内剩下的anchor中,除开与GT的iou大于一定阈值的(v2是0.6,v3是0.5),其它的anchor全部标为负样本.\n",
    "   \n",
    "   这种忽略高于一定阈值anchor的方式,减轻了正负样本不均的现象,同时也减少了hard-neg的数量,更加合理.  \n",
    "    \n",
    "    \n",
    "11. YOLOv3的多尺度输出结构与FPN有何不同？  \n",
    "    YOLOv3的多尺度融合时,使用的是concatenate,而FPN使用的是pixel-wise add.  \n",
    "\n",
    "\n",
    "12. YOLOv2,v3的anchor聚类如何做？指标是什么？  \n",
    "    * 首先先对每个bbox的wh都做归一化\n",
    "    * 然后,再从所有的bbox里选出9个作为初始的参考bbox\n",
    "    * 把所有的bbox都和初始的9个bbox算iou,1-iou作为指标\n",
    "    * 然后根据每个box对应的最小距离聚类\n",
    "    * 对聚到的9个类的box的hw求平均,均值为新的参考wh再重新聚类\n",
    "    * 直到每个box对应的类别(9个anchor的id)不变为止  \n",
    "\n",
    "\n",
    "13. FPN的多尺度输出结构与SSD的多尺度输出结构哪个效果更好?\n",
    "    FPN的方式更加合理,因为它融合了高分辨率信息与高语义信息  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. faster-rcnn在撒anchor的时候，是如何把特征图坐标映射到图像上的？  \n",
    "    $$(\\lfloor{s/2}\\rfloor+xs,\\lfloor{s/2}\\rfloor+ys)$$,其中s为stride,x,y为输出特征图上点的坐标  \n",
    "    \n",
    "15. faster-rcnn的OHEM与ssd的OHEM有何不同?  \n",
    "    对于faster-rcnn,在RCNN阶段，从2000个ROI里选择正负样本时，除了正样本之外，负样本的选择按照head出来的**cls_loss**选择，选择loss最大的（num-pos_num）个参加训练,对于FPN来说,num=512\n",
    "    对于SSD,正负样本比例在1:3,负样本的选择也是依据**cls_loss**来选  \n",
    "    \n",
    "16. roi pooling与roi align的具体操作  \n",
    "    首先，ROI pooling 和 ROI Align 是为了解决这样的问题：对于 RPN 生成的不同大小的 proposal， 我们都需要传入全连接神经网络，而我们知道全连接神经网络建立之后就对输入尺寸产生了限制，因此我们需要保证不同的 proposal 都变换到既能表达其原本特征，又能传入 FCN 的结果。在 Fast RCNN 和 Faster RCNN 中则分别采用了 ROI pooling 和 ROI Align 这两种操作。 \n",
    "\n",
    "    1. ROI pooling 是对特征图进行划分，例如，若 FCN 的输入需要统一到 49，则划分 proposal 成 7 * 7 的格子，并在每个格子中取最大值进行下采样获得结果。\n",
    "\n",
    "    但是我们可以发现，并不是所有的特征图对应的 bbox 在下采样之后都可以整除。也就是 ROI pooling在操作过程中会经过两次取整量化，第一次是在输入图片下采样到$x/s$(faster rcnn中s是16)，此时 ROI 也许不会是整数，那么就需要取整之后对应到特征图。之后进行7 * 7的划分，划分得到的每个小矩形的边长依旧可能是小数，则需要再进行一次取整，这样两次取整之后，获得的下采样的 bbox 对应到原图已经有了较大差距。从而产生特征偏差。\n",
    "\n",
    "    2. 与 ROI pooling 不同，ROI Align 则不进行任何取整操作，而是根据浮点数的 bbox 在特征图上划分成 n * n 份 ROI grid，再把每一小份平分成 4 份（若采样率为4，分到的成为bin），每一个bin的中心点位置通过双线性插值从周围的网格中获得，再对 4 个 bin 做 max-pooling 作为当前 ROI grid的值，这个过程中没有引入任何的取整，从而把离散操作化为连续操作，并减少了误差。  \n",
    "    ![avatar](./Pics/mr_f1.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "17. retinanet解决了以往one-stage检测器的什么问题\n",
    "\n",
    "    正负样本不均衡的问题,two-stage的模型由于利用rpn晒掉了大量的负样本,所以在rcnn阶段不会出现明显的正负样本不均衡的问题  \n",
    "    \n",
    "    \n",
    "18. Focal loss一定有效吗？为什么？试举出一个例子 \n",
    "\n",
    "    不一定有效.Focal loss在计算的时候,loss在reduction时除以的只有pos_num. Focal loss在训练YOLOv3的时候起的是degrade的作用.\n",
    "    \n",
    "    \n",
    "19. 介绍cascade-RCNN和DCN模块。Cascade-rcnn解决了什么问题？cascade-RCNN一般选用几个阶段？ \n",
    "\n",
    "    介绍cascade-RCNN就会涉及到IoU。Faster-RCNN通过RoI与标签的IoU值来判断这个RoI是正样本还是负样本。这个IoU阈值是一个超参数，对于检测的精度有着较大的影响。因此IoU值的选择很重要。\n",
    "    2018年CVPR上的cascade-RCNN算法通过级联多个检测器来不断优化结果，每一个检测器的边框输出都作为下一个检测器的输入，每个检测器都基于不同的IoU阈值来界定正负样本，而且检测器的IoU阈值是逐渐提升的。IoU阈值越高，检测器的定位更加准确，但是会导致正负样本更加不均衡，容易过拟合；阈值越低，正样本更多，有利于训练，但是误检也会增多。因此，这种级联方式的检测器可以逐步过滤掉一些误检框，同时能够逐步提升边框的定位精度。\n",
    "    总而言之，cascade-RCNN算法深入探讨了IoU阈值对检测器性能的影响，能够在不增加任何trick的前提下，在多个数据集上都有了明显的精度提升，是一个性能优越的高精度目标检测器。\n",
    "    ![avatar](./Pics/cascade-RCNN.png)\n",
    "    3个阶段的时候准确率已经很高了，第四阶段已经没有增益了。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. anchor-free的方式大概分为哪两种？各有什么特点？\n",
    "    center-based(FCOS),keypoint-based(centernet,cornernet...)\n",
    "    \n",
    "21. coco的mAP的计算公式  \n",
    "    大概介绍(比较清晰)可见 https://zhuanlan.zhihu.com/p/56961620  \n",
    "    代码角度介绍可见 https://zhuanlan.zhihu.com/p/79186684 与 https://zhuanlan.zhihu.com/p/79208756  \n",
    "    * 首先固定到某一类c,按照score从大到小排序,注意这里是对所有图片的c类box    \n",
    "    * 卡一个iou阈值(voc是0.5,coco是(0.5,0.95,0.005)的浮动),按照topk的方法算出按score排序的前k个预测的precision(查准率)与recall(查全率)  \n",
    "    * 根据所得P-R值绘制P-R曲线,对P-R曲线进行平滑,平滑规则是$$p(r)=max_{\\bar{r}>r}p(\\bar{r})$$  \n",
    "    * 对P-R曲线用11点法(早期)或者包围面积法(现在普遍)计算AP,若是VOC规则,则对每一类求AP,平均后即可得mAP,若是COCO,则先对每一个IOU阈值下的AP取平均,再对每一类取平均.即VOC的mAP只取一次平均,COCO的mAP取两次平均."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. 为什么 Faster RCNN 相较 YOLO v2 更慢？\n",
    "   网络的推断速度取决于计算量，因此可以从网络结构和模块组成两个方面来分析。\n",
    "   1. 网络结构：在 Faster RCNN 中最复杂的网络就是用于特征提取的 backbone，对于不同的 backbone 就会对网络推断速度产生较大的影响，VGG 网络作为backbone 往往就会使得推断较慢。\n",
    "   2. 模块组成：我们发现 Faster RCNN 相对于 one-stage 的网络多出了 RPN 网络，同时为了适应 FCN 还有 ROI pooling 和 ROI Align 模块，因此其是需要提取很多的 proposals 才能进行分类，而不是像一阶段网络将 proposal 生成和判断同时进行，并需要每次对 proposals 进行 ROI pooling 和 ROI Align 较费时间。\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.循环卷积神经网络\n",
    "1. LSTM为什么会导致梯度爆炸？要如何解决？\n",
    "    1. 参数化的遗忘门控制流向下一个时间步的信息量\n",
    "    2. 梯度裁剪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.语义分割\n",
    "1. 主要语义分割的算法有哪些，他们有什么区别？\n",
    "  \n",
    "  语义分割实际上是像素级的图像分类任务，其需要网络能提取较大感受野范围的信息，对物体的整体感知确定这个物体是什么，同时根据上下文以及物体的纹理等细节信息来分辨不同物体，并在分辨之后在保留物体的位置信息的前提下上采样恢复到原图大小的标签；因此语义分割中的关键在于两点：1，同时感受不同尺度的特征信息来区分物体类别。2.在下采样丢失位置信息的情况下，正确恢复位置信息\n",
    "  \n",
    "  对于这些问题，我们可以采用增加感受野，并同时感受不同感受野的物体，主要方法有：\n",
    "  1. Unet 中将浅层和深层的特征通过跳接对应相加，也就在两个不同感受野上处理问题，但是也存在对接时位置可能没有对应的问题\n",
    "  2. PSPNet 对在 backbone 提取特征之后进行不同尺度的池化结果进行上采样融合，即通过池化增加感受野，并和之前没有池化的结果对应得到结果\n",
    "  3. Deeplab v3+ 在 backbone 提取特征之后采用不同尺度空洞卷积和全局池化获得不同感受野信息，并对应底层信息来进行位置校正，最后获得分割结果。（空洞卷积是一个增加感受野的很好的额方式，但是对于在特征提取后期进行空洞卷积会相对增加计算量，同时还会又可能增加对一些重要信息的忽略）\n",
    "  \n",
    "  下面仔细介绍一下几个典型的分割网络：明显增加了计算代价。B.空洞卷积是一种coarse sub-sampling，因此容易损失重要信息。\n",
    "  #### 1. FCN(全卷积网络)\n",
    "  \n",
    "  根据深度学习网络不仅需要高级语义信息并需要高分辨率的信息的基础上，在 VGG 分类网络的基础上替换后面三层的全连接层为卷积神经网络，获取更高分辨率的特征输出，并对输出进行三次上采样（转置卷积实现），每次上采样都将上采样的结果和对应结果的平均池化相加，从而获得多视野的特征感知。最后一次上采样则获得分割结果。\n",
    "  \n",
    "  总结：\n",
    "  1. 去除FC：去除全连接层的操作获得了更强的位置信息\n",
    "  2. 转置卷积上采样：通过上采样得到了更高分辨率的结果，用于精细化的预测\n",
    "  3. 融合特征提取之后的一层特征和上一级特征：三次上采样分别和上层的结果拼接，但是没有同时获取不同尺度的特征图和对比底层的特征使得其对特征的感知还是不够。\n",
    "  \n",
    "  其网络结构如下：\n",
    "  ![img](./Pics/FCN.jpg)\n",
    "  \n",
    "  #### 2. Unet\n",
    "  其通过设计 U 型的 Encoder-Decoder 网络结构，首先通过四次下采样对网络进行特征提取，之后进行四次上采样对网语义进行进行恢复，同时每次恢复时对底层对应的特征进行复制，crop 和 concatenate，通过这样的操作提取高级语义信息的同时对初级的语义进行进行了结合，从而基于高级和低级语义特征同时进行预测。\n",
    "\n",
    "  总结：\n",
    "  1. 参数量小：Unet的网络本身仅 28M，在缩减 channels 之后还能更小，因此非常适合数据量少的情况也能减少过拟合\n",
    "  2. 同时吸收底层和高级特征信息，对称的结构一定程度上保存了位置信息，因此对应位置同时利用高级和低级特征进行判断可以帮助分割\n",
    "  3. 使用膨胀预测和数据增强的方式来进行训练，膨胀预测图例如下:\n",
    "    ![img](./Pics/overlap.jpg)\n",
    "\n",
    "  其网络结构如下：\n",
    "    ![img](./Pics/Unet.jpg)\n",
    "\n",
    "  #### 3. SegNet \n",
    "  在 SegNet 中，其依旧使用 Unet 中的 Encoder-Decoder 结构，但是其使用了一个特别的方式来还原位置信息，即在每次 pooling 下采样之后，都会记住 pooling 的位置信息，并用于在之后的 unpool 中进行对应位置信息的还原，这样也就保证特征的位置得以保存。\n",
    "  \n",
    "  总结：\n",
    "  1. Encoder-Decoder 结构，没有同时使用底层和高层信息\n",
    "  2. 在 pooling 标记 Index 用于恢复位置信息\n",
    "  3. 使用 Vgg 和反转的 Vgg 来作为 Encoder 和Decoder\n",
    "  \n",
    "  其网络结构如下：\n",
    "    ![img](./Pics/segnet.jpg)\n",
    "    \n",
    "  #### 4. Deeplab  v3+ \n",
    "  通过 resnet/xception 作为 backbone 进行特征提取之后，我们获得了降采样 8 倍 / 16 倍的特征图，同时还有经过 backbone 某几层生成的基础特征用于辅助信息；在主要特征图的基础上，Deeplab 进行了 ASPP，也就是将特征图按照不同的 dialation rate 进行下采样，还有进行一次全局池化，从而获得不同感受野的特征图；对这些特征图进行上采样到和底层特征维度一致之后进行 concatenate，最后对这样的集合特征进行卷积并上采样就获得了最终的结果。\n",
    "  \n",
    "  总结：\n",
    "  1. 多种方法多尺度特征感受：使用包括 backbone 中的空洞卷积，ASPP，底层特征卷积后 concatenate 三种方式进行不同感受野的合并和感知\n",
    "  2. 采用 xception 网络来提升速度和效果：但是在笔者的实验得出，使用 resnet152 和 xception 进行训练和预测的速度并无差异，但是 xception 网络的训练结果在精度和 mIOU 上相比 resnet152 下降了 2% 和 20% 模型体积从 573M 下降到 419M。\n",
    "  3. 将 Dialation rate 最大的替换成全局平均池化，减少了最大尺度的空洞卷积，避免其采样到很多 padding 的0元素得到无用信息。\n",
    "  \n",
    "  其网络结构如下：\n",
    "  ![img](./Pics/deeplabv3.png)\n",
    "  \n",
    "  #### 5. PSPNet(金字塔场景分割网络)  \n",
    "  PSPNet 以其特殊的金字塔结构闻名，即将网络在经过 resnet152 进行特征提取之后，提取的特征再次经过输出大小分别为 1，2，3，6 的平均池化，得到结果经过 conv 减少通道数并上采样获得和原来特征相同大小，并将些特征进行双线性上采样得到结果。如果使用辅助分支的话，还会对原来的特征进行双线性插值，获得最后的分割结果并用于计算损失。\n",
    "  \n",
    "  总结：\n",
    "  1. 全局平均池化构造特征金字塔用于多尺度感受\n",
    "  2. 底层特征直接上采样得到结果用于后续损失更新\n",
    "  \n",
    "  其网络结构如下：\n",
    "  ![img](./Pics/psp.png)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 感受野会受到什么因素的影响？怎么影响？\n",
    "感受野是网络中某个神经元对原输入图像的感受范围的大小， stride, 卷积神经网络的深度，池化操作，空洞卷积层中 dialation rate 设置都会影响。\n",
    "其计算公式如下:\n",
    "\n",
    "    本层的kernelsize * 上一层的感受野 -（上一层kernelsize-1） * （上一层的感受野-前面stride的连乘积） 其中rn代表第n层的感受野，kn，sn代表第n层的kernel size，stride\n",
    "\n",
    "    ![Pics/Untitled%205.png](Pics/Untitled%205.png)\n",
    "\n",
    "    [深度神经网络中的感受野(Receptive Field)](https://zhuanlan.zhihu.com/p/28492837)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.遥感图像语义分割和普通图像的语义分割有什么区别？\n",
    "* **波段信息的不同**：遥感图像和普通数据的区分是遥感数据相对于其他数据增加了新的波段信息，除了可见光的波段，遥感图片还会有 NIR （近红外波段）， SWIR （短波红外）， MIR （中波红外）， LIR （长波红外）等不同波段；而之所以有这么多的波段是因为在高远处的不同类别的图像的特征容易混淆，而增加新的波段能给网络提供更多的信息。\n",
    "* **利用不同波段区分**：因此，我们可以根据不同波段的数据增加信息来判断，例如在普通可见光下的森林和草地区别不大，但是当我们利用上近红外的信息之后，就会发现森林更加偏红，从而区分不同的图像。这一点在标注时很有用，那么在网络训练上也理应获得不错的效果\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.语义分割中的样本不均衡介绍一下？\n",
    "\n",
    "**不平衡场景下学习困难的来源**:\n",
    "1. **不同类别样本数量不均匀**，导致大类在损失函数中主导，小样本信息难以回传并学习到：在数据集中存在某一些类别的样本很多，另一些类别样本很少；从而在深度学习模型中，多类样本占据了损失函数中的主导部分，从而小类样本的损失小，梯度回传少，网络学习少，网络预测结果不准确。\n",
    "3. **不同类别样本分布重叠**，线性不可分的数据集，导致分解平面需要更加扭曲：样本不均衡导致分类准确度下降的原因除了大类和小类的比例不均，还有是因为小类样本和大类样本的重叠，即不同类样本分布的重叠，如下图所示，同一列代表多少样本的比例相同，可以发现，当不同类别样本分布重叠，分类器需要学习到一个复杂得多的分类边界，从而需要更加复杂的模型来处理：\n",
    "2. **小类样本受中噪声的影响更大**，一味拟合所有小样本会容易过拟合：在少量数据中存在的噪声对原本就少的样本的分布影响大，一旦网络学习了噪声的信息，就会过拟合训练集，无法学习到真正代表少量样本的分布。\n",
    "\n",
    "![img](./Pics/samplebias.jpg)\n",
    "\n",
    "**解决样本不均衡**：要解决样本不均衡的问题，我们一般从下面两个个方面入手：\n",
    "1. [样本重采样](https://zhuanlan.zhihu.com/p/66373943)(解决数量不均匀问题)：将数据集进行重采样，这里又分为欠采样和过采样，欠采样和过采样都是希望样本的大类和小类的数量能更加地平衡，从而网络能更加平衡地学习而不产生过拟合或者欠拟合。\n",
    "    1. 欠采样是通过距离度量等方式，希望保留原样本结构地同时减少大类样本，这种方法能减少样本增加运行效率，但是筛选过程也比较费事，同时对于语义分割这样整体的任务不好实施。\n",
    "    2. 过采样则是基于少量样本生成新的数据，希望能基于原小类样本的数据结构进行样本生成，但是当小类样本数量少或者有噪声时效果会不甚理想。\n",
    "    3. 数据融合：在有多个数据集时，对不同的数据集进行融合，促使有较少类别的样本能获得其他数据集的样本，促进样本均衡。这个方法需要将图片切块之后进行人工/算法筛选，其往往会引入新的数据结构，但是由于是基于现实数据，其对最终的结果还是能有一定提升。\n",
    "\n",
    "2. 损失函数均衡（解决数量不均匀问题）：由于主要的问题是大类别的损失函数占主导作用，那么我们通过权重的方式促使小类别的权重增加，从而网络能更多学习这些小类别的样本。但是，我们不能一味考虑学习少量样本，我们还需要考虑到样本中离群点的影响，为了避免离群点的影响，我们需要用梯度范数去规范网络的学习。目前针对损失的提升方法有：[Focal Loss，GHM](https://zhuanlan.zhihu.com/p/80594704)，[Dice Loss，加权交叉熵损失](https://zhuanlan.zhihu.com/p/103426335)等方法\n",
    "\n",
    "3. 集成学习（解决噪声影响和分布重叠问题），由于集成学习能综合多个判别边界，因此对于噪声有一定抵抗作用，从而使用集成学习如随机森林（决策树bagging，解决过拟合）或者xgboost也能帮助解决样本不平衡的问题。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.Backbone\n",
    "1. resnet中的恒等快捷连接在前向传播和反向传播都有什么作用？\n",
    "    1. 在前向传播时可以将不同尺度的特征图进行相加，一起分析，提升对不同尺度的感受程度\n",
    "    2. 在反向时，通过直连，使得梯度可以直接到达浅层神经网络，缓解梯度传播不流畅的问题（即深层网络的梯度能直接传播到浅层网络）\n",
    "    3. 缓解权值退化问题，即近似恒等的映射难以用堆叠非线性层的方式去实现的问题。\n",
    "    4. 在恒等映射的基础上去学习恒等映射之外的扰动，帮助网络的学习更加精细化\n",
    "\n",
    "ps：resnet 中依旧没有做到完全的浅层特征图直接连接到后层，而是跟了一个非线性激活层，因此在 resnet v2 中有将非线性激活层前移形成 pre-activation，保证了恒等连接并提升了精度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.卷积神经网络基础\n",
    "1. Batch Normalization 在卷积神经网络中的作用是什么?\n",
    "\n",
    "    通过将一个通道的所有特征图，进行归一化并再一次进行仿射变换。\n",
    "\n",
    "    **因此BN的作用就是通过规范每一层神经网络输出的分布，限制前层输出分布变化带来的后层输入的不稳定，从而引起的链式反应。**\n",
    "\n",
    "    1. 在使用sigmoid/tanh激活函数时，限制神经元的输出范围，使得输出落在激活函数梯度较大的区域，避免梯度消失的情况，同样可以减少梯度爆炸的情况\n",
    "    2. 在深层网络中限制浅层神经网络输出的变化范围，避免深层神经元对变化大的浅层神经元输出的不断适应导致的训练不稳定问题\n",
    "    3. 将有不同量纲的变量统一到一个范围内，有利于学习\n",
    "    4. 起到正则化的效果，因为限制输出的范围，从而将输出空间大大减小，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 1\\*1卷积的作用是什么？\n",
    "\n",
    "    - 1×1卷积核可以起到一个跨通道聚合的作用，所以进一步可以起到降维（或者升维）的作用，起到减少参数的目的；\n",
    "    - 并且实现了不同channel上的特征融合\n",
    "    - 同时由于卷积层之后都会增加一个激活层，因此 1\\*1 卷积也可以为网络提供更多的非线性\n",
    "    - 充当全连接层的作用，减少卷积层到全连接层之间的显式数据转换（4维张量的flatten操作）\n",
    "    \n",
    "    PS: 在深度可分离卷积（ Xception ）和 Inception 中对 1 * 1 的卷积核都有所应用，他们两个网络都是应用了 1 * 1卷积单独做通道维的特征提取，这样和空间维的特征提取分离，促使更加独立的特征聚合的作用，并且这样一定程度上利用了三维矩阵分解的思想(信息解耦合，促进特征更好学习)，有助于参数量的减少。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. [深度可分离卷积](https://www.zhihu.com/tardis/sogou/art/80041030)介绍一下?\n",
    "    \n",
    "* 深度可分离卷积实际上是 Inception 的拓展，Inception 提倡把空间维和通道维的特征提取进行分离，从而实现信息解耦和参数量的减少。而 Xception 则将这一点做的更加极致。\n",
    "    \n",
    "* **Inception中的特征提取解耦**：在 Inception 中我们先进行了 1 * 1 的卷积，之后再进行了通道和空间复合的常规卷积，这样一定程度上还是没有实现完全解耦。\n",
    "    \n",
    "* **Xception 中的特征提取解耦**：在 Xception 中，作者则是先对每个通道进行了空间维卷积（即通道为 1 仅做空间维的卷积），之后对这些卷积结果进行 1 * 1卷积，这样就实现了完全解耦\n",
    "    \n",
    "* **Xception 中的参数量变化**：常规卷积的参数量是 K * K * C_in * C_out，Xception 中 K * K * C_in + 1 * 1 * C_out\n",
    "\n",
    "* **深度可分离卷积和普通卷积的计算量差异**：\n",
    "\n",
    "我们已知常规卷积的计算量为：$$C_{out}*C_{in}*(\\frac{H-K+P_{H}}{S}+1)*(\\frac{W-K+P_{W}}{S}+1)*K*K$$\n",
    "\n",
    "深度可分离卷积的计算量为：$$C_{in}*K*K*(\\frac{H-K+P_{H}}{S}+1)*(\\frac{W-K+P_{W}}{S}+1)+ C_{in}*1*1*(\\frac{H-K+P_{H}}{S}+1)*(\\frac{W-K+P_{W}}{S}+1)*C_{out}$$\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 两层较小的卷积核和一个较大的卷积核比较，各有什么缺点和优点？\n",
    "两个3\\*3的卷积核在没有 padding 和 stride 为 1 的情况下，感受野和一层 5\\*5 的卷积核相同，但是参数量为 9\\*2/25。\n",
    "    1. 多层较小的卷积神经核在达到相同感受野的情况下，可以实现参数量的减少，因此减小显存的占用\n",
    "    2. 多层的显著效果是使得网络层加深，那么加深的网络层在 sigmoid / tanh 层的作用下可能会存在梯度消失/爆炸的问题。\n",
    "    3. 但也不排除使得因为网络加深核中间插入的非线性激活层使得网络的表达能力变强，从而能更好地拟合数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 不同激活函数有什么区别？\n",
    "    1. sigmoid函数：其梯度值变化范围为（0-1/4）同时输入值特别大或者特别小的时候求出来的梯度特别小，因此在网络较深时，梯度叠加起来导致梯度消失\n",
    "\n",
    "        $$f(z) = {1/(1+exp(-z))}; f'(z) = f(z)(1-f(z))$$\n",
    "\n",
    "    2. tanh 函数：其导数范围为（0，1），网络较深导致梯度消失；输入相对sigmoid来说输出正负都有，更加平衡\n",
    "\n",
    "        $$f(z) = tanh(z) = (e^{z} - e^{-z})/(e^{z}+e^{-z});  f'(z) = 1-(f(z))^2$$\n",
    "\n",
    "    3. Relu函数：反向传播时不需要计算指数，相比说来计算量更小；因为不容易梯度消失，因此更多的神经元能有效激活；一定程度上促进稀疏性(神经元前向传播为负数时，该神经元就被杀死了，因此相当于变相的dropout)；但是在学习率过大是有可能导致一些神经元的不可逆死亡（学习率过大时，部分神经元一下更新到不合适的参数，因此，无论什么输入，输出都是负值）Leaky ReLU输入小于0的部分用很小的斜率，有助于缓解这个问题（即便输入是负数，也不会完全没有梯度更新）。\n",
    "\n",
    "        $$f(z) = max(0,z); f'(z) = 1/0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.卷积层输出大小的计算\n",
    "\n",
    "* 一个 H1\\*W1 的特征图，加上上下左右加上 padding，用长度为 k 的 kernel，stride 进行卷积。\n",
    "* 输出的卷积层大小为：(H1+2\\*padding-k)/stride + 1\n",
    "\n",
    "5.1.卷积层中计算量的计算：\n",
    "* ~~Floating point operations per second (FLOPS, flops or flop/s): 每秒浮点数计算次数，一个浮点数计算次数代表一次乘加，则计算量如下~~FLOPs：注意s小写，是floating point operations的缩写（s表复数），意指浮点运算数（量），理解为计算量。可以用来衡量算法/模型的复杂度。\n",
    "$$C_{out}*C_{in}*(\\frac{H-K+P_{H}}{S}+1)*(\\frac{W-K+P_{W}}{S}+1)*K*K$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Dropout层为什么可以促进正则化？pytorch中dropout在训练与测试时如何使用？\n",
    "\n",
    "Dropout 通过不断抛去一些神经元，限制了网络的表达能力，从而起到了正则化的效果。Pytorch 中，训练时网络的所有单元以概率 p 丢弃，剩余的单元的输出乘以（1/1-p），测试的时候直接使用所有单元。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 平方误差损失函数和交叉熵损失函数分别适用于什么场景？\n",
    "    1. MSE更加适应输出为连续变化，并且最后一层不含softmax和sigmoid的神经网络，交叉熵更加适合分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 梯度消失/爆炸的原因：\n",
    "    1. 消失：由于 Sigmoid 等函数容易饱和的特性，使得反向传播时可能会有多个小于一的值相乘，从而使得梯度消失\n",
    "    2. 爆炸：卷积层参数w*  激活函数的导数值大于1，连乘之后就变成一些很大的数值，这个可以通过梯度截断，损失函数权重正则化，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 损失降不下来怎么办？\n",
    "    1. 检查是否采用了合适的损失函数，分类用交叉熵，回归用MSE\n",
    "    2. 检查输入数据是否成功配对\n",
    "    3. 检查学习率和学习策略是否正确\n",
    "    4. 网络是否过于简单，没有合适的拟合能力\n",
    "\n",
    "10. weight decay vs L2 正则项：\n",
    "       weight decay 是在更新网络权重的时候，减去一个权重很小的一部分（比如说lambda1 = 0.0005），其直接作用在网络权重更新上，直接减少权重。L2正则项则是作用在损失函数上，使得网络权重在更新时也会减去权重本身的一部分，一般来说当正则项的惩罚系数设置成（lambda2 = lambda1/2），可以等效两种正则系数。\n",
    "\n",
    "    ![weight decay vs L2 正则项](Pics/Untitled%206.png)                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![L1 正则项 vs L2 正则项](./Pics/Untitled%207.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. avarage-pooling 与 max-pooling的区别与联系？它们的梯度反传如何进行？  \n",
    "    Pooling的结果是使得特征减少，特征图的参数量降低，但pooling目的实际在于保持众多不变性（旋转、平移、伸缩等），即减少网络对于物体位置的敏感程度，同时降低网络对于特征图细节的敏感性，并增加感受野。\n",
    "    根据相关理论，特征提取的误差，这里误差是和任务相关的关键特征例如点，线，pattern，和卷积网络输出特征图之间的差距。导致这个误差的原因是卷积核没有覆盖足够大感受野（和 pattern 重叠），从而捕捉不到特征/因为卷积核参数不对导致捕捉不到对任务有用的关键信息。因此总结下来，误差主要来自两个方面：\n",
    "    * 卷积核的感受野大小受限造成的估计值方差增大；\n",
    "    * 卷积层参数误差造成估计均值的偏移。  \n",
    "\n",
    "    mean-pooling能减小第一种误差（邻域大小受限造成的估计值方差增大），更多的保留图像的背景信息，  \n",
    "    max-pooling能减小第二种误差（卷积层参数误差造成估计均值的偏移），更多的保留纹理信息。  \n",
    "    &ensp;&ensp;&ensp;&ensp;avg-pooling实际上是一个线性操作，而max-pooling是一个非线性的操作，因此网络中间层使用max-pooling也是考虑到了其非线性的特点，提高网络的复杂度。pooling会有信息损失，在segmentation等有encoder-decoder功能的网络里会降低性能。但是反过来说，池化也有防止过拟合的作用  \n",
    "\n",
    "    两种pooling的梯度反传\n",
    "    ![avatar](./Pics/mean_pooling.jpeg)\n",
    "    ![avatar](./Pics/max_pooling.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 各种normalization层了解多少？  \n",
    "    ![avatar](./Pics/n.png)  \n",
    "    * BN：  \n",
    "        1.BN的计算就是把每个通道的NHW单独拿出来归一化处理   \n",
    "\n",
    "        2.针对每个channel我们都有一组γ,β，所以可学习的参数为2*C  \n",
    "\n",
    "        3.当batch size越小，BN的表现效果也越不好，因为计算过程中所得到的均值和方差不能代表全局  \n",
    "\n",
    "    * LN：  \n",
    "        1.LN的计算就是把每个CHW单独拿出来归一化处理，不受batchsize的影响\n",
    "\n",
    "        2.常用在RNN网络，但如果输入的特征区别很大，那么就不建议使用它做归一化处理  \n",
    "\n",
    "    * IN：  \n",
    "\n",
    "        1.IN的计算就是把每个HW单独拿出来归一化处理，不受channel和batchsize 的影响  \n",
    "\n",
    "        2.常用在风格化迁移，但如果特征图可以用到通道之间的相关性，那么就不建议使用它做归一化处理  \n",
    "\n",
    "    * GN：  \n",
    "\n",
    "        1.GN的计算就是把先把通道C分成G组，然后把每个gHW单独拿出来归一化处理，最后把G组归一化之后的数据合并成CHW\n",
    "\n",
    "        2.GN介于LN和IN之间，当然可以说LN和IN就是GN的特列，比如G的大小为1或者为C  \n",
    "\n",
    "        **补充：关于GN，详细可见 https://www.cnblogs.com/jins-note/p/11342565.html**  \n",
    "\n",
    "        **GN解决了BN的两个问题：1.依赖于batchsize，bs太小时，性能明显下降 2.测试数据与训练数据有差时，会造成mean与var的不一致**  \n",
    "\n",
    "        **GN为什么work：每一层有很多的卷积核，这些核学习到的特征并不完全是独立的，某些特征具有相同的分布，因此可以被group**\n",
    "\n",
    "    * Switchable Normalization：\n",
    "\n",
    "        1.将 BN、LN、IN 结合，赋予权重，让网络自己去学习归一化层应该使用什么方法\n",
    "\n",
    "        2.集万千宠爱于一身，但训练复杂  \n",
    "\n",
    "    * **SyncBN**：  \n",
    "\n",
    "        SyncBN具体可见链接https://zhuanlan.zhihu.com/p/69940683 与 https://www.cnblogs.com/makefile/p/batch-norm.html?utm_source=debugrun&utm_medium=referral **主要解决了在数据并行时,BN的mean和var分开统计的问题**\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. 为什么学习率的设置要与batchsize成线型关系?  \n",
    "    具体可见 https://www.zhihu.com/question/64134994/answer/216895968 。总的来说有以下三点：  \n",
    "    * 大batch的数据梯度方差小，噪声小，可以用大lr提高收敛速度。从方差的角度上看，更大的batch意味着一个mini-batch中样本的方差更小，也同时意味着一个mini-batch带来的梯度方差也更小，梯度更加可信，噪声给模型带来的影响也会相应减少，在可信的梯度下，我们可以使用更大的learning rate来更新参数，提高收敛速度是可行的。  \n",
    "    * 适当的增大learning rate还可以有效避免模型走到一个比较差的local minima  \n",
    "    * 决定收敛快慢的有三个因素：梯度好坏，步幅（lr），步数（iter）。在epoch不变的情况下，大的batch造成iter要小，就是说步数要小，这个时候增大步幅才可以避免因为步数少而不收敛的情况。公式上的解释可以参考链接  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. ReLU有哪些改进的方式  \n",
    "    详见 https://www.cnblogs.com/XDU-Lakers/p/10557496.html 与 https://blog.csdn.net/weixin_41417982/article/details/81437088?utm_source=blogxgwz9  \n",
    "    主要有以下的改进方式：\n",
    "    ![avatar](./Pics/relu.png)  \n",
    "    其中LReLU解决了Dead relu的问题。因为Leaky ReLU保留了x小于0时的梯度，在x小于0时，不会出现神经元死亡的问题。对于Leaky ReLU给出了一个很小的负数梯度值α，这个值是很小的常数。比如：0.01。这样即修正了数据分布，又保留了一些负轴的值，使得负轴信息不会全部丢失。但是这个α通常是通过先验知识人工赋值的。  \n",
    "    PRElu的α是加入训练得到的，Rrelu的α在训练的时候是从一个高斯分布中随机取出来的，然后在测试的过程中，把训练过程中所有的α取个平均值。  \n",
    "\n",
    "\n",
    "15. 神经网络中参数中的偏置bias有什么作用  \n",
    "    bias平移拟合曲线，可以更好地拟合数据。比如对于sigmoid，若想在x=2的时候使得输出等于0，那么无论怎么改变w都很难做到，只能做平移取得。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. 转置卷积和反卷积的区别？（这个问题的[参考文章](https://towardsdatascience.com/what-is-transposed-convolutional-layer-40e5e6e31c11)）\n",
    "    1. 转置卷积是希望在进行卷积，转置卷积之后能保持输出的性质和输入的相同，因此，我们需要对应输入卷积的参数计算转置卷积中的参数。计算结果如下：\n",
    "    ![img](./Pics/transposed.png)\n",
    "    而我们可以通过下列公式计算给定输入和相关参数时的输出，不过这里的 padding, stride 参数都是卷积操作中的参数。\n",
    "    ![img](./Pics/transequa.png)\n",
    "    下面给出一些不同参数下的转置卷积的结果\n",
    "    ![img](./Pics/transposed_result.gif)\n",
    "    \n",
    "    2. 反卷积则是希望能完全撤回卷积操作的影响，他们之间的差异通过下面的图可以很好说明。即转置卷积只需要保持形状不变，而反卷积需要保持形状和内容的不变性\n",
    "    ![img](./Pics/detrans.png)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. 什么是空洞卷积，它的感受野如何计算？ 给定 dialation rate 为 Drate 的卷积核，他的输出和输入大小的对应关系又是什么？ \n",
    "   \n",
    "   空洞卷积是为了增加卷积核的感受野而设计，它通过在卷积核的每个神经元的采样过程中增加间隔（也称作 Dialation rate），帮助固定参数量的卷积核能感受到上一层更多的信息（在后面我们可以看到，这是因为减少了感受野计算时神经元之间的重叠）。\n",
    "   ![img](./Pics/dialated.gif)\n",
    "                                       图：kernel = 3, padding = 0, dialation = 1的空洞卷积\n",
    "   在计算感受野时，我们依旧遵循 当前层感受野 = 最大可获取的感受野 - 重叠的个数 * 两两神经元之间重叠多少 的公式\n",
    "   那么其实对于空洞卷积，唯一变化的就是两两神经元之间重叠多少的部分，经过仔细观察发现，dialation rate 实际是对 stride 的一个补充，也就是当前层的 stride'= stride*(dialation + 1)。那么，讲下面公式中的 stride 相应地替换就能得到结果\n",
    "   ![img](./Pics/receptive_field.svg)\n",
    "   \n",
    "   在计算输出和输入对应关系时，我们则只需要将 kernel size 进行扩充，即 kernel_size' = kernel_size + (kernel_size -1 ) * Drate 即可  \n",
    "   \n",
    "   ![img](./Pics/inout.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.神经网络训练场景问题\n",
    "1. 怎么判断过拟合，怎么处理？\n",
    "\n",
    "过拟合是由于模型太过复杂或者数据太少，导致的模型过度拟合训练样本的个性，从而导致用该模型预测其他样本结果时和真实值差异过大\n",
    "    \n",
    "   1. 通常以dropout层、添加噪声、或网络随机过程的某种形式进行\n",
    "   2. 增加数据多样性，例如数据集增强等\n",
    "   3. 提早结束\n",
    "   4. batch normalization\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Python\n",
    "1. 装饰器是什么，有什么作用？\n",
    "\n",
    "在代码运行期间动态增加功能的方式，称之为“装饰器”（Decorator），装饰器时一个返回函数的高阶函数。\n",
    "\n",
    "装饰器一般会使用python的@语法，在函数定义时进行在函数前一行执行@decorator，就相当于 令func = decorator(func)，即把func传入decorator函数，并使func等于decorator返回的函数（比如说是func2）。而func2内部可以在返回func调用的基础上再增加一些额外的功能，那么也就在不改变原来函数的基础上增加了额外的功能。\n",
    "\n",
    "import functools\n",
    "\n",
    "def log(func):\n",
    "        @functools.wraps(func)   # 保留now在decorator调用之后的函数属性\n",
    "    def wrapper(*args, kw):\n",
    "        print('call %s():' % func.__name__)\n",
    "        return func(*args, kw)\n",
    "    return wrapper\n",
    "\n",
    "@log            ##等效于 now = log(now)\n",
    "def now():\n",
    "    print('2015-3-25')\n",
    "\n",
    "2. 迭代器：代表了一个惰性的有序序列，提前并不知道序列的长度\n",
    "\n",
    "可以被for循环作用的成为可迭代对象iterable：比如集合数据类型：list，tuple，dict，set，str等；以及生成器和生成函数\n",
    "可以被next调用并不断生成下一个值的对象叫做iterator，例如生成器和被iter() 函数转换的集合数据类型\n",
    "\n",
    "3. 生成器：\n",
    "\n",
    "Python中，这种一边循环一边计算的机制，称为生成器：generator。\n",
    "\n",
    "创建一个生成器只需要将list中的 [] 改为()，并使用next()/for循环函数进行调用；或者也可以通过函数内部+yield 生成生成器，并用for循环获取生成值\n",
    "  \n",
    "4. 深拷贝与浅拷贝的区别\n",
    "\n",
    "深拷贝是对拷贝内存地址中的内容进行复制，复制到一个新的内存地址中，从而获得一个新的对象，那么你对这个对象的修改就不会影响原来的对象。\n",
    "而使用浅拷贝呢，则是重新建立了一个指向被拷贝对象的指针，通过对这个指针访问可以访问原来的对象，但是对这个拷贝对象的修改则也会对原来的变量有影响，同时我们可以发现，浅拷贝的对象的 id，即内存地址和被拷贝对象的相同，说明他们是指向同一个内存地址中的对象。\n",
    "\n",
    "5. Python中is和==的区别\n",
    "\n",
    "is是用来判断两个变量引用的对象是否为同一个；==用于判断引用对象的值是否相等。（可以通过id()函数查看引用对象的地址）\n",
    "\n",
    "6. 解释with语句\n",
    "\n",
    "关键字with在不再需要访问文件后将其关闭。在with语句中，我们只调用open()，但不调用close();你也可以调用open()和close()来打开和关闭文件，但这样做时，如果程序存在bug，导致close()语句未执行，文件将不会关闭。这看似微不足道，但未妥善地关闭文件可能会导致数据丢失或受损。如果在程序中过早地调用close()，你会发现需要使用文件时它已关闭(无法访问)，这会导致更多的错误。并非在任何情况下都能轻松确定关闭文件的恰当时机，但通过使用with结构的语句，可让Python去确定:你只管打开文件，并在需要时使用它，Python自会在合适的时候自动将其关闭。\n",
    "\n",
    "7. 什么是面向对象？面向过程和面向对象的区别？\n",
    "\n",
    "面向对象和面向过程都只是解决问题的一种思路而已。\n",
    "面向过程：将数据与函数按照执行的逻辑顺序组织在一起，数据与函数是分开的，由于从上到下写代码，代码会很长；\n",
    "面向对象：将数据与函数绑定到一起，进行封装，这样能够快速地开发程序，减少了重复代码的重写过程。\n",
    "面向对象的三大特性：封装，继承，多态。\n",
    "简而言之，面向过程就是所有步骤、过程都需要亲自去实现，而面向对象则是创建、调用一个拥有这些方法的对象，并令该对象执行。\n",
    "面向对象也是基于面向过程的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 9.机器学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.讲讲支持向量机，间隔，对偶，核技巧，如何将分类问题转化成最优化问题的（手推公式）？\n",
    "\n",
    "关于支持向量机，强烈建议观看[shuhuai的视频](https://www.bilibili.com/video/BV1Hs411w7ci?p=6)\n",
    "\n",
    "**定义**：针对线性可分数据/线性不可分数据的分类算法，优化最大间隔分类器问题，得到在现有数据上有最大分类间隔的分界面。\n",
    "\n",
    "**分类**：\n",
    "1. 硬间隔支持向量机： 对于每个数据均分类正确且具有最大分类间隔分界面的分类器\n",
    "2. 软间隔支持向量机：对于部分噪声数据/少量非线性可分数据进行分类，得到最后结果容许少量的分类错误\n",
    "3. 带 kernel 支持向量机： 将非线性可分数据进行高维映射（高维数据比低维数据更加容易线性可分）\n",
    "\n",
    "**SVM 标准型的推导思路**：详细推导过程见[这里](https://github.com/ws13685555932/machine_learning_derivation)\n",
    "1. 建立最大间隔分类器的优化问题：\n",
    "2. 其中间隔的定义为最小的数据点到分界面的距离（点到直线距离），\n",
    "3. 分类器（100% 正确分类）则是在最优化限制条件中保证样本点（xi）有当标签为+1时，在分界面的上方，在标签为-1时，在分界面的下方。\n",
    "4. 在这个限制条件下优化最大间隔的问题即可以求解到SVM的分界面参数w，b\n",
    "5. 在这个问题上不断推导就可以得到 SVM 问题的标准形式，如下图：\n",
    "![img](./Pics/SVM.png)\n",
    "\n",
    "**求解 SVM 问题思路**\n",
    "SVM 的标准型为二次规划问题，在w，b维度较小的时候可以使用二次规划求解套路求解，但是在w，b较复杂/数据过多时，需要使用下列思路进行求解\n",
    "1. 将有约束问题转化为无约束问题：通过拉格朗日乘子法进行转换，其中原本的约束在求解外围最小时得到保证\n",
    "2. 将无约束问题转换为其对偶问题，进一步简化计算，其中这一步的前提为对偶问题和原问题具有强对偶性（这个需要证明对偶问题满足KKT条件进行证明），并根据无约束对偶问题求导获得最优参数\n",
    "3. 使用KKT条件，求解出最终的参数\n",
    "\n",
    "![IMG](./Pics/KKT.png)\n",
    "\n",
    "**软间隔 SVM 标准型的推导思路**\n",
    "软间隔即在硬间隔的基础上能允许分类器犯错，因为不需要去过度拟合无用数据，例如噪声等，因此，软间隔分类器能实现更好的泛化性能\n",
    "1. 软间隔允许加上分类不正确的损失\n",
    "2. 同时在限制条件上更加宽松，在支持向量们所在分界面的平行平面们之间允许存在数据\n",
    "\n",
    "![img](./Pics/softmargin.png)\n",
    "\n",
    "**带核的 SVM 解决思路**\n",
    "带核的SVM 和 SVM 在模型上并无不同，只是通过对数据通过正定核函数进行转换，获得线性可分的更高维数据，在这个线性可分的数据上进行分类。\n",
    "1. 找到正定核函数，其能直接得到两个数据的内积，方便我们进行w，b的计算\n",
    "2. 对数据的核函数下的内积进行求解并带入到w，b的公式求解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.讲解逻辑回归和手写逻辑回归的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 简单介绍一下集成学习？\n",
    "\n",
    "集成学习是通过集合多个互补模型实现提高准确率减少过拟合等目标的一个模型集成方法。集成学习包含 bagging，boosting，stacking 等\n",
    "\n",
    "**1. bagging**：通过不同而强大的独立观点避免对于噪声和离群点的过拟合\n",
    "   bagging 通过有放回采样的方法生成不同的数据集，并基于这些数据集进行模型的训练获得一些互补的可能有过拟合的一系列网络，并在最后通过 Averaging/Voting 的方式来获得减少过拟合的结果。\n",
    "\n",
    "  一个典型的例子就是随机森林，即将容易过拟合的决策树通过 Bagging 的方式组合起来，平滑决策边界，减少过拟合，其算法流程如下：\n",
    "\n",
    " **算法流程**：\n",
    "   1. 用 N 来表示训练用例（样本）的个数，M 表示特征数目。\n",
    "   2. 从 N 个样本中以有放回抽样的方式，取样 N 次，形成一个训练集（即bootstrap取样），并用未抽到的样本作预测，评估其误差（Out of Bag Error Estimation）。\n",
    "   3. 对于每一个节点，随机选择 m 个特征，决策树上每个节点的决定都是基于这些特征确定的。根据这 m 个特征，计算其最佳的分裂方式。（需要随机限制对一些特征的访问来获得不同的决策树）\n",
    "   4. 重复第 2，3 步骤得到 K 棵子树\n",
    "   5. 测试数据分别通过 K 棵子树获得预测结果，预测结果进行平均/投票获得最终结果\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.讲解逻辑回归和手写逻辑回归的损失函数？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 简单介绍一下集成学习？\n",
    "\n",
    "集成学习是通过集合多个互补模型实现提高准确率减少过拟合等目标的一个模型集成方法。集成学习包含 bagging，boosting，stacking 等\n",
    "\n",
    "**1. bagging**：通过不同而强大的独立观点避免对于噪声和离群点的过拟合\n",
    "   bagging 通过有放回采样的方法生成不同的数据集，并基于这些数据集进行模型的训练获得一些互补的可能有过拟合的一系列网络，并在最后通过 Averaging/Voting 的方式来获得减少过拟合的结果。\n",
    "\n",
    "  一个典型的例子就是随机森林，即将容易过拟合的决策树通过 Bagging 的方式组合起来，平滑决策边界，减少过拟合，其算法流程如下：\n",
    "\n",
    " **算法流程**：\n",
    "   1. 用 N 来表示训练用例（样本）的个数，M 表示特征数目。\n",
    "   2. 从 N 个样本中以有放回抽样的方式，取样 N 次，形成一个训练集（即bootstrap取样），并用未抽到的样本作预测，评估其误差（Out of Bag Error Estimation）。\n",
    "   3. 对于每一个节点，随机选择 m 个特征，决策树上每个节点的决定都是基于这些特征确定的。根据这 m 个特征，计算其最佳的分裂方式。（需要随机限制对一些特征的访问来获得不同的决策树）\n",
    "   4. 重复第 2，3 步骤得到 K 棵子树\n",
    "   5. 测试数据分别通过 K 棵子树获得预测结果，预测结果进行平均/投票获得最终结果\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Boosting** ：Boosting 是基于一个表现得比乱猜稍微好一些的判别器，不断调整数据的权重，获得不同判别边界的组合来得到最终正确的判别边界\n",
    "   其不断根据当前模型的表现调整数据集中数据的权重，即对错误的数据增加权重来获得新的数据集，基于新的数据集串行训练获得错误率更低的模型，最终通过错误率加权不同模型的输出结果，获得逐渐完美的判别边界。算法流程如下：\n",
    "\n",
    "  **算法流程**：\n",
    "   1. 基于数据训练一个过得去的分类器（正确率大于50%）\n",
    "   2. 调整数据集：将当前分类器中错分的样本增加权重，没有错分的样本减少权重，增加/减少权重系数为 d = sqrt((1-Error)/Error)\n",
    "   3. 基于新的数据集训练一个差不多的分类器\n",
    "   4. 重复 2，3 获得一系列分类器，通过证明我们知道，最终的错误率会小于Π_i 2 * sqrt（Error_i*(1-Error_i)），即样本权重之和/N,对于所有分类器的预测结果使用 ln(sqrt((1-Error)/Error)) 进行加权即得到最终的结果。\n",
    "\n",
    "  **问题**：\n",
    "  1. Adaboost 这样的 boosting 方法能促进分类器的在训练集上的分类效果不断变好，那么它会不会在测试集上泛化性能变差呢？\n",
    "  不会，其在训练集上的结果越来越好却并不会过拟合，通过推导我们可以知道，不断训练 Adaboost 可以促使 y * g(x) 的数值不断增大，也就是容错率增加，那么即便在训练样本上的结果已经很好，我们不断进行 boosting 训练还能促使 test 上的结果越来越好。也就是训练的过程并不会导致过拟合\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1 Gradient Boosting**：\n",
    "\n",
    "从一个较弱的分类器开始，设立一个目标损失函数，不断学习一个这个分类器的残差，使得最后的损失函数越来越小，当我们把损失设置为 $$L = -\\exp(y_{gt}*g_{t}(x))$$ 时，其结果和 Adaboost 等效，同时残差函数的权重也和 Adaboost 中的相同。\n",
    "   \n",
    "但是 Gradient boosting 的思想其实更加具有一般性，其思想为求得使得特定损失越来越小的模型/目标函数，求取目标函数过程为对损失函数求导来从而优化目标函数来优化损失；同时设置新的函数应该为之前的函数加上现有的残差，那么目标函数就有两个限定条件来优化，为了两个限定条件同时满足，那么就将其相乘后优化最大，之后得到目标函数的优化结果。这样将反向梯度传播到学习后的函数身上并让函数不断在学习残差中改进的过程，就能学习到越来越好的函数。\n",
    "\n",
    "   **算法流程**：\n",
    "   1. 设定一个针对目标函数的优化目标，例如目标函数在训练样例上的输出和给定标签相同，并使用 CELOSS/MSELOSS 来表达。\n",
    "   2. 写出目标函数的迭代方程，后一项等于前一项加上一个带权的残差函数。\n",
    "   3. 基于第一项求导，得到优化目标函数的梯度，该梯度和第二项方向相同，从而最大化乘积得到残差函数。\n",
    "   4. 确定学习率：损失函数对学习率求导=0， 得到最合适的学习率。\n",
    "   5. 通过学习率和残差函数优化目标函数，并重复2-4步得到最终结果。\n",
    "    \n",
    "![IMG](./Pics/GB.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Stacking**：使用神经网络基于没有见过的训练数据将不同的系统的输出进行整合的方式\n",
    "与 Bagging 里简单的平均组合不同， stacking 希望依靠一些没有使用过的训练数据学习到将不同系统输出结果进行组合的方式，从而可以尽量减少不好系统的结果的影响，生成更好的输出结果。其算法流程如下：  \n",
    "   **算法流程**：\n",
    "       1. 将数据分为训练集 1 ，训练集 2 ，验证集和测试集\n",
    "       2. 使用训练集 1 按照 Bagging 的方式训练出多个不同的分类器，使用训练集 2 训练一个浅层神经网络，其以第一层的输出为输入，希望获得一个良好的输出。\n",
    "       3. 将四个不同的系统使用浅层神经网络的综合结果用于验证和测试\n",
    "![img](./Pics/stacking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging vs Boosting：\n",
    "1. 样本选择上：\n",
    "Bagging：训练集是在原始集中有放回选取的，从原始集中选出的各轮训练集之间是独立的。\n",
    "Boosting：每一轮的训练集不变，只是训练集中每个样例在分类器中的权重发生变化。而权值是根据上一轮的分类结果进行调整。\n",
    "\n",
    "2. 样例权重：\n",
    "Bagging：使用均匀取样，每个样例的权重相等\n",
    "Boosting：根据错误率不断调整样例的权值，错误率越大则权重越大。\n",
    "\n",
    "3. 预测函数：\n",
    "Bagging：所有预测函数的权重相等。\n",
    "Boosting：每个弱分类器都有相应的权重，对于分类误差小的分类器会有更大的权重。\n",
    "\n",
    "4. 并行计算：\n",
    "Bagging：各个预测函数可以并行生成\n",
    "Boosting：各个预测函数只能顺序生成，因为后一个模型参数需要前一轮模型的结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 10.传统图像处理\n",
    "1. 直方图均衡  \n",
    "    详见https://blog.csdn.net/schwein_van/article/details/84336633 简单来讲，就是计算累积直方图（积分），累积直方图得到的新的变量服从均匀分布，所以称为直方图均衡化。  \n",
    "    \n",
    "2. 直方图匹配  \n",
    "    详见https://blog.csdn.net/majinlei121/article/details/46482615 两幅图都做均衡后（积分），像素级之间相减，创建一个256 * 256的矩阵，矩阵每一行代表这个灰度级与另一张图的每个灰度级的差别，对每一行做个argmin操作，索引到的灰度级就是要映射的灰度级。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. SIFT的特点  \n",
    "    1.SIFT特征是图像的局部特征，其对旋转、尺度缩放、亮度变化保持不变性，对视角变化、仿射变换、噪声也保持一定程度的稳定性；  \n",
    "    2.区分性（Distinctiveness）好，信息量丰富，适用于在海量特征数据库中进行快速、准确的匹配；  \n",
    "    3.多量性，即使少数的几个物体也可以产生大量的SIFT特征向量；  \n",
    "    4.高速性，经优化的SIFT匹配算法甚至可以达到实时的要求；  \n",
    "    5.可扩展性，可以很方便的与其他形式的特征向量进行联合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 刚体变换，仿射变换，透视变换（投影变换）  \n",
    "    详见 https://zhuanlan.zhihu.com/p/74597564  \n",
    "    * 刚体变换：物体的旋转以及平移，不改变物体的形状。  \n",
    "    * 仿射变换：改变物体位置和形状，但是保持“平直性”，即直线还是直线，原来平行的线还是平行的。  \n",
    "    * 透视变换：彻底改变物体位置和形状  \n",
    "    * 仿射变换是特殊的透视变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 索贝尔算子长什么样?为什么长这样?  \n",
    "    **索贝尔算子是一阶差分算子,求图像的梯度**\n",
    "    ![avatar](./Pics/sobel.jpg)  \n",
    "\n",
    "    Sobel算子根据像素点上下、左右邻点灰度加权差，在边缘处达到极值这一现象检测边缘。对噪声具有平滑作用，提供较为精确的边缘方向信息，边缘定位精度不够高。当对精度要求不是很高时，是一种较为常用的边缘检测方法。  \n",
    "\n",
    "    ![avatar](./Pics/sobel_2.jpg)  \n",
    "\n",
    "    可以看到Sobel算子对图像的处理过程，本质是一次差分、一次平滑的连续运算。其中[1 0 -1]及其转置，分别表示水平差分和垂直差分；[1 2 1]及其转置，分别代表水平平滑和垂直平滑。  \n",
    "\n",
    "    ![avatar](./Pics/equation1.svg)  \n",
    "    ![avatar](./Pics/equation2.svg)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 拉普拉斯边算子?  \n",
    "    **拉普拉斯算子是二阶差分算子,求图像的二阶导数**\n",
    "    ![avatar](./Pics/laplace.svg)  \n",
    "    ![avatar](./Pics/laplace_e.jpg)  \n",
    "    **sobel与拉普拉斯边缘检测的区别**:  \n",
    "    * 索贝尔具有明确的方向性(垂直与水平).图片旋转一定角度,其提取效果就会下降  \n",
    "    * laplace算子具有旋转不变性,这一点可以从它的模板中心对称可以看出来,但是laplace对于噪声(特别是平滑区域的孤立点)更加敏感,这一点可以从laplace算子的计算式可以看出.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 图像亮度、对比度、饱和度 \n",
    "**图像亮度、对比度、饱和度和锐化之间并不是彼此独立的，改变其中一个特征可能会同时引起图像其他特征的变化**  \n",
    "    https://zhuanlan.zhihu.com/p/44813768  \n",
    "    https://blog.csdn.net/qq_37385726/article/details/82526396  \n",
    "    亮度:图像的明暗成都  \n",
    "    饱和度:饱和度指的是图像颜色种类的多少， 上面提到图像的灰度级是[Lmin，Lmax]，则在Lmin、Lmax 的中间值越多，便代表图像的颜色种类多，饱和度也就更高，外观上看起来图像会更鲜艳，调整饱和度可以修正过度曝光或者未充分曝光的图片  \n",
    "    对比度:指的是图像暗和亮的落差值，即图像最大灰度级和最小灰度级之间的差值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 高斯金字塔与拉普拉斯金字塔\n",
    "    https://zhuanlan.zhihu.com/p/80362140\n",
    "    ![avatar](./Pics/laplace.png)\n",
    "    高斯金字塔是个不断低通滤波的过程,拉普拉斯金字塔是个带通滤波  \n",
    "    高斯金字塔下采样的过程:  \n",
    "    * 对图像G_i进行高斯内核卷积\n",
    "    * 将所有偶数行和列去除  \n",
    "    拉普拉斯金字塔上采样的过程:  \n",
    "    * 将图像在每个方向扩大为原来的两倍，新增的行和列以0填充  \n",
    "    * 使用先前同样的内核(乘以4)与放大后的图像卷积，获得 “新增像素”的近似值  \n",
    "    其中使用的高斯核都是:  \n",
    "    ![avatar](./Pics/gk.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. LBP特征和其等价模式?\n",
    "  \n",
    "**原始的LBP 特征**是判断一个图像中间的位置的像素值和周围8邻域的相对大小，领域中像素值小于中间的设置为0，否则设置为1，最后对其串行编码得到LBO特征，这个特征能帮助我们提取图片中的重点信息，用于人脸识别等方面。\n",
    "\n",
    "随后，为了增加LBP特征的***旋转不变性**，对其进行了改进\n",
    "\n",
    "同时，为了能对LBP特征更好地存储，定义了LBP等价模式，即在特征中邻居跳变不超过两次的模式为**等价模式**\n",
    "\n",
    "具体的资料详见[这里](https://www.cnblogs.com/wanghui-garcia/p/12626925.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
